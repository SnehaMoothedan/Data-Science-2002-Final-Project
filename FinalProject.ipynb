{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e92b89-10fd-4ecd-83d7-9e9307de67cb",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "## Part 1: Prerequisites\n",
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75975be8-bf81-4ecb-b746-383b052eb81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\spark-3.5.4-bin-hadoop3\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print(findspark.find())\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pymongo\n",
    "import certifi\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window as W\n",
    "\n",
    "import math\n",
    "import builtins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff01d9-7570-4cd1-b212-7991b2e1e6a7",
   "metadata": {},
   "source": [
    "### Instantiating global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdbe96a-6fb6-407a-817c-af2edb7542f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Specify MySQL Server Connection Information\n",
    "# --------------------------------------------------------------------------------\n",
    "mysql_args = {\n",
    "    \"host_name\" : \"localhost\",\n",
    "    \"port\" : \"3306\",\n",
    "    \"db_name\" : \"adventureworks\",\n",
    "    \"conn_props\" : {\n",
    "        \"user\" : \"sneham\",\n",
    "        \"password\" : \"password\",\n",
    "        \"driver\" : \"com.mysql.cj.jdbc.Driver\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Specify MongoDB Cluster Connection Information\n",
    "# --------------------------------------------------------------------------------\n",
    "mongodb_args = {\n",
    "    \"cluster_location\" : \"atlas\", # \"atlas\"\n",
    "    \"user_name\" : \"snehasmoothedan\",\n",
    "    \"password\" : \"password101\",\n",
    "    \"cluster_name\" : \"Sandbox\",\n",
    "    \"cluster_subnet\" : \"eylzz\",\n",
    "    \"db_name\" : \"adventureworks\",\n",
    "    \"collection\" : \"\",\n",
    "    \"null_column_threshold\" : 0.5\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Specify Directory Structure for Source Data\n",
    "# --------------------------------------------------------------------------------\n",
    "base_dir = os.path.join(os.getcwd(), 'data')\n",
    "data_dir = os.path.join(base_dir, 'adventureworks')\n",
    "mongo_dir = os.path.join(data_dir, 'mongodb')\n",
    "batch_dir = os.path.join(data_dir, 'batch')\n",
    "stream_dir = os.path.join(data_dir, 'streaming')\n",
    "\n",
    "purchase_orders_stream_dir = os.path.join(stream_dir, 'purchase_orders')\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Create Directory Structure for Data Lakehouse Files\n",
    "# --------------------------------------------------------------------------------\n",
    "dest_database = \"adventureworks_dlh\"\n",
    "sql_warehouse_dir = os.path.abspath('spark-warehouse')\n",
    "dest_database_dir = f\"{dest_database}.db\"\n",
    "database_dir = os.path.join(sql_warehouse_dir, dest_database_dir)\n",
    "\n",
    "purchase_orders_output_bronze = os.path.join(database_dir, 'fact_purchase_orders', 'bronze')\n",
    "purchase_orders_output_silver = os.path.join(database_dir, 'fact_purchase_orders', 'silver')\n",
    "purchase_orders_output_gold = os.path.join(database_dir, 'fact_purchase_orders', 'gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3189e12f-ace8-4403-8254-f11610a5657c",
   "metadata": {},
   "source": [
    "### Defining global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b724d5a-573a-445b-bc6f-968761c4d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_info(path: str):\n",
    "    file_sizes = []\n",
    "    modification_times = []\n",
    "\n",
    "    '''Fetch each item in the directory, and filter out any directories.'''\n",
    "    items = os.listdir(path)\n",
    "    files = sorted([item for item in items if os.path.isfile(os.path.join(path, item))])\n",
    "\n",
    "    '''Populate lists with the Size and Last Modification DateTime for each file in the directory.'''\n",
    "    for file in files:\n",
    "        file_sizes.append(os.path.getsize(os.path.join(path, file)))\n",
    "        modification_times.append(pd.to_datetime(os.path.getmtime(os.path.join(path, file)), unit='s'))\n",
    "\n",
    "    data = list(zip(files, file_sizes, modification_times))\n",
    "    column_names = ['name','size','modification_time']\n",
    "    \n",
    "    return pd.DataFrame(data=data, columns=column_names)\n",
    "\n",
    "\n",
    "def wait_until_stream_is_ready(query, min_batches=1):\n",
    "    while len(query.recentProgress) < min_batches:\n",
    "        time.sleep(5)\n",
    "        \n",
    "    print(f\"The stream has processed {len(query.recentProgress)} batchs\")\n",
    "\n",
    "\n",
    "def remove_directory_tree(path: str):\n",
    "    '''If it exists, remove the entire contents of a directory structure at a given 'path' parameter's location.'''\n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "            return f\"Directory '{path}' has been removed successfully.\"\n",
    "        else:\n",
    "            return f\"Directory '{path}' does not exist.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "        \n",
    "\n",
    "def drop_null_columns(df, threshold):\n",
    "    '''Drop Columns having a percentage of NULL values that exceeds the given 'threshold' parameter value.'''\n",
    "    columns_with_nulls = [col for col in df.columns if df.filter(df[col].isNull()).count() / df.count() > threshold] \n",
    "    df_dropped = df.drop(*columns_with_nulls) \n",
    "    \n",
    "    return df_dropped\n",
    "    \n",
    "    \n",
    "def get_mysql_dataframe(spark_session, sql_query : str, **args):\n",
    "    '''Create a JDBC URL to the MySQL Database'''\n",
    "    jdbc_url = f\"jdbc:mysql://{args['host_name']}:{args['port']}/{args['db_name']}\"\n",
    "    \n",
    "    '''Invoke the spark.read.format(\"jdbc\") function to query the database, and fill a DataFrame.'''\n",
    "    dframe = spark_session.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", jdbc_url) \\\n",
    "    .option(\"driver\", args['conn_props']['driver']) \\\n",
    "    .option(\"user\", args['conn_props']['user']) \\\n",
    "    .option(\"password\", args['conn_props']['password']) \\\n",
    "    .option(\"query\", sql_query) \\\n",
    "    .load()\n",
    "    \n",
    "    return dframe\n",
    "    \n",
    "\n",
    "def get_mongo_uri(**args):\n",
    "    '''Validate proper input'''\n",
    "    if args[\"cluster_location\"] not in ['atlas', 'local']:\n",
    "        raise Exception(\"You must specify either 'atlas' or 'local' for the 'cluster_location' parameter.\")\n",
    "        \n",
    "    if args['cluster_location'] == \"atlas\":\n",
    "        uri = f\"mongodb+srv://{args['user_name']}:{args['password']}@\"\n",
    "        uri += f\"{args['cluster_name']}.{args['cluster_subnet']}.mongodb.net/\"\n",
    "    else:\n",
    "        uri = \"mongodb://localhost:27017/\"\n",
    "\n",
    "    return uri\n",
    "\n",
    "\n",
    "def get_spark_conf_args(spark_jars : list, **args):\n",
    "    jars = \"\"\n",
    "    for jar in spark_jars:\n",
    "        jars += f\"{jar}, \"\n",
    "    \n",
    "    sparkConf_args = {\n",
    "        \"app_name\" : \"PySpark Adventureworks Data Lakehouse (Medallion Architecture)\",\n",
    "        \"worker_threads\" : f\"local[{int(os.cpu_count()/2)}]\",\n",
    "        \"shuffle_partitions\" : int(os.cpu_count()),\n",
    "        \"mongo_uri\" : get_mongo_uri(**args),\n",
    "        \"spark_jars\" : jars[0:-2],\n",
    "        \"database_dir\" : sql_warehouse_dir\n",
    "    }\n",
    "    \n",
    "    return sparkConf_args\n",
    "    \n",
    "\n",
    "def get_spark_conf(**args):\n",
    "    sparkConf = SparkConf().setAppName(args['app_name'])\\\n",
    "    .setMaster(args['worker_threads']) \\\n",
    "    .set('spark.driver.memory', '4g') \\\n",
    "    .set('spark.executor.memory', '2g') \\\n",
    "    .set('spark.jars', args['spark_jars']) \\\n",
    "    .set('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1') \\\n",
    "    .set('spark.mongodb.input.uri', args['mongo_uri']) \\\n",
    "    .set('spark.mongodb.output.uri', args['mongo_uri']) \\\n",
    "    .set('spark.sql.adaptive.enabled', 'false') \\\n",
    "    .set('spark.sql.debug.maxToStringFields', 35) \\\n",
    "    .set('spark.sql.shuffle.partitions', args['shuffle_partitions']) \\\n",
    "    .set('spark.sql.streaming.forceDeleteTempCheckpointLocation', 'true') \\\n",
    "    .set('spark.sql.streaming.schemaInference', 'true') \\\n",
    "    .set('spark.sql.warehouse.dir', args['database_dir']) \\\n",
    "    .set('spark.streaming.stopGracefullyOnShutdown', 'true')\n",
    "    \n",
    "    return sparkConf\n",
    "\n",
    "\n",
    "def get_mongo_client(**args):\n",
    "    '''Get MongoDB Client Connection'''\n",
    "    mongo_uri = get_mongo_uri(**args)\n",
    "    if args['cluster_location'] == \"atlas\":\n",
    "        client = pymongo.MongoClient(mongo_uri, tlsCAFile=certifi.where())\n",
    "\n",
    "    elif args['cluster_location'] == \"local\":\n",
    "        client = pymongo.MongoClient(mongo_uri)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"A MongoDB Client could not be created.\")\n",
    "\n",
    "    return client\n",
    "    \n",
    "    \n",
    "# TODO: Rewrite this to leverage PySpark?\n",
    "def set_mongo_collections(mongo_client, db_name : str, data_directory : str, json_files : list):\n",
    "    db = mongo_client[db_name]\n",
    "    \n",
    "    for file in json_files:\n",
    "        db.drop_collection(file)\n",
    "        json_file = os.path.join(data_directory, json_files[file])\n",
    "        with open(json_file, 'r') as openfile:\n",
    "            json_object = [json.loads(line) for line in openfile]\n",
    "            file = db[file]\n",
    "            result = file.insert_many(json_object)\n",
    "        \n",
    "    mongo_client.close()\n",
    "    \n",
    "\n",
    "def get_mongodb_dataframe(spark_session, **args):\n",
    "    '''Query MongoDB, and create a DataFrame'''\n",
    "    dframe = spark_session.read.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "        .option(\"database\", args['db_name']) \\\n",
    "        .option(\"collection\", args['collection']).load()\n",
    "\n",
    "    '''Drop the '_id' index column to clean up the response.'''\n",
    "    dframe = dframe.drop('_id')\n",
    "    \n",
    "    '''Call the drop_null_columns() function passing in the dataframe.'''\n",
    "    dframe = drop_null_columns(dframe, args['null_column_threshold'])\n",
    "    \n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76487c6-7f86-4670-a6be-f685a43624b6",
   "metadata": {},
   "source": [
    "### Initializing Data Lakehouse Directory Structure\n",
    "Removing the current Date Lakehouse Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c2e906-98a5-41fd-84a5-bc8c0b74c49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Directory 'C:\\\\Users\\\\sneha\\\\Documents\\\\Spring Sem 2025\\\\DS2002\\\\Final Project\\\\spark-warehouse\\\\adventureworks_dlh.db' has been removed successfully.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_directory_tree(database_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c28eb-b3ff-49ca-8fc3-e98c815bcb2e",
   "metadata": {},
   "source": [
    "### Creating a new Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383c4bf9-c08e-4e4a-8612-b646ff20b509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-G7BLNMTO:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySpark Adventureworks Data Lakehouse (Medallion Architecture)</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x17567ed2790>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker_threads = f\"local[{int(os.cpu_count()/2)}]\"\n",
    "\n",
    "jars = []\n",
    "mysql_spark_jar = os.path.join(os.getcwd(), \"mysql-connector-j-9.1.0\", \"mysql-connector-j-9.1.0.jar\")\n",
    "mssql_spark_jar = os.path.join(os.getcwd(), \"sqljdbc_12.8\", \"enu\", \"jars\", \"mssql-jdbc-12.8.1.jre11.jar\")\n",
    "\n",
    "jars.append(mysql_spark_jar)\n",
    "#jars.append(mssql_spark_jar)\n",
    "\n",
    "sparkConf_args = get_spark_conf_args(jars, **mongodb_args)\n",
    "\n",
    "sparkConf = get_spark_conf(**sparkConf_args)\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"OFF\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e79b2b-fc11-4b7a-9581-12ea4f75c33d",
   "metadata": {},
   "source": [
    "### Creating a new metadata database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53217c09-8591-4eff-802e-57b5ed9828d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DROP DATABASE IF EXISTS {dest_database} CASCADE;\")\n",
    "\n",
    "sql_create_db = f\"\"\"\n",
    "    CREATE DATABASE IF NOT EXISTS {dest_database}\n",
    "    COMMENT 'DS-2002 Final Project'\n",
    "    WITH DBPROPERTIES (contains_pii = true, purpose = 'DS-2002 Final Project');\n",
    "\"\"\"\n",
    "spark.sql(sql_create_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6a34c8-370e-42fe-b92d-a6730f62757d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>modification_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vendor.csv</td>\n",
       "      <td>8448</td>\n",
       "      <td>2025-05-07 18:21:54.641071796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  size             modification_time\n",
       "0  vendor.csv  8448 2025-05-07 18:21:54.641071796"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_info(batch_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da7f86-47d3-4222-acc5-e2ac2debed3b",
   "metadata": {},
   "source": [
    "## Creating JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5391ff-bee6-448f-9590-d7c892f64b20",
   "metadata": {},
   "source": [
    "### For MongoDB\n",
    "Creating the JSON file for the employee data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9192bc73-2b19-4796-a62e-75bdd1f54dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_employee = f\"SELECT * FROM {mysql_args['db_name']}.employee\"\n",
    "df_employee = get_mysql_dataframe(spark, sql_employee, **mysql_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9832ff0-9429-4494-8a45-8b0393d23942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employee = df_employee.coalesce(1)\n",
    "temp_dir = \"data/adventureworks/temp\"\n",
    "df_employee.write.mode(\"overwrite\").json(temp_dir)\n",
    "\n",
    "for file in os.listdir(temp_dir):\n",
    "    if file.startswith(\"part-\") and file.endswith(\".json\"):\n",
    "        part_file = file\n",
    "        break\n",
    "\n",
    "shutil.move(os.path.join(temp_dir, part_file), \"data/adventureworks/mongodb/employee.json\")\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299d3bb3-ab59-401d-8921-3a1cc5e8d6cb",
   "metadata": {},
   "source": [
    "#### Uploading the file onto MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "856cfba0-f037-4d49-b6d2-3783e72dd078",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_mongo_client(**mongodb_args)\n",
    "json_files = {\"employee\" : 'employee.json'}\n",
    "\n",
    "set_mongo_collections(client, mongodb_args[\"db_name\"], mongo_dir, json_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb3c6ef-b4fc-4cd6-a6da-84c62daa1cb8",
   "metadata": {},
   "source": [
    "### For local file\n",
    "Creating one local CSV file for vendors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8fd9382-c918-4a24-8a0a-3db8302944d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_vendor = f\"SELECT * FROM {mysql_args['db_name']}.vendor\"\n",
    "df_vendor = get_mysql_dataframe(spark, sql_vendor, **mysql_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2dcc0c8-c500-41b5-82f3-45d8022fc07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vendor = df_vendor.coalesce(1)\n",
    "temp_dir = \"data/adventureworks/temp\"\n",
    "df_vendor.write.mode(\"overwrite\").option(\"header\", True).csv(temp_dir)\n",
    "\n",
    "for file in os.listdir(temp_dir):\n",
    "    if file.startswith(\"part-\") and file.endswith(\".csv\"):\n",
    "        part_file = file\n",
    "        break\n",
    "\n",
    "shutil.move(os.path.join(temp_dir, part_file), \"data/adventureworks/batch/vendor.csv\")\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f785918b-98bc-4f98-9b69-4ee4e9453843",
   "metadata": {},
   "source": [
    "### For Spark\n",
    "Splitting the fact table data into three parts and saving them as JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e1a5e05-032c-45be-bb24-3c0e900ab954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_spark_dataframe_to_single_json_files(df, base_filename, output_dir=\".\", num_parts=3):\n",
    "    total_rows = df.count()\n",
    "    rows_per_part = math.ceil(total_rows / num_parts)\n",
    "\n",
    "    for i in range(num_parts):\n",
    "        start_idx = i * rows_per_part\n",
    "        \n",
    "        end_idx = builtins.min((i + 1) * rows_per_part, total_rows)\n",
    "        df_part = df.limit(end_idx).subtract(df.limit(start_idx))\n",
    "\n",
    "        temp_path = os.path.join(output_dir, f\"tmp_{base_filename}_{i+1}\")\n",
    "        df_part.coalesce(1).write.mode(\"overwrite\").json(temp_path)\n",
    "\n",
    "        for fname in os.listdir(temp_path):\n",
    "            if fname.startswith(\"part-\") and fname.endswith(\".json\"):\n",
    "                src_path = os.path.join(temp_path, fname)\n",
    "                dest_path = os.path.join(output_dir, f\"{base_filename}_{i+1}.json\")\n",
    "                shutil.move(src_path, dest_path)\n",
    "                break\n",
    "\n",
    "        shutil.rmtree(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86320cc3-598a-444d-9589-27c01e09502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_po_header = f\"SELECT * FROM {mysql_args['db_name']}.purchaseorderheader\"\n",
    "df_po_header = get_mysql_dataframe(spark, sql_po_header, **mysql_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a741e221-47d2-49ea-93ab-684a0e6eba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_spark_dataframe_to_single_json_files(df_po_header, base_filename=\"po_part\", output_dir=\"data/adventureworks/streaming\", num_parts=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0746638c-bab9-4f87-bd7c-bc5bdec99aae",
   "metadata": {},
   "source": [
    "## Part 2: Populating the dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52424a91-4198-433f-a8eb-a7a78d5c8ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>modification_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vendor.csv</td>\n",
       "      <td>8448</td>\n",
       "      <td>2025-05-07 18:39:08.228654861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  size             modification_time\n",
       "0  vendor.csv  8448 2025-05-07 18:39:08.228654861"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_info(batch_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce4123b-4b4d-4109-95c7-feec0e96232c",
   "metadata": {},
   "source": [
    "### Populating the Vendors Dimension\n",
    "Using PySpark to read data from the vendors.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "919c208c-51eb-4418-90d8-3e33c21d4a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneha\\Documents\\Spring Sem 2025\\DS2002\\Final Project\\data\\adventureworks\\batch\\vendor.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>AccountNumber</th>\n",
       "      <th>Name</th>\n",
       "      <th>CreditRating</th>\n",
       "      <th>PreferredVendorStatus</th>\n",
       "      <th>ActiveFlag</th>\n",
       "      <th>PurchasingWebServiceURL</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>INTERNAT0001</td>\n",
       "      <td>International</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2002-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ELECTRON0002</td>\n",
       "      <td>Electronic Bike Repair &amp; Supplies</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2002-02-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID AccountNumber                               Name  CreditRating  \\\n",
       "0         1  INTERNAT0001                      International             1   \n",
       "1         2  ELECTRON0002  Electronic Bike Repair & Supplies             1   \n",
       "\n",
       "   PreferredVendorStatus  ActiveFlag PurchasingWebServiceURL ModifiedDate  \n",
       "0                   True        True                    None   2002-02-25  \n",
       "1                   True        True                    None   2002-02-17  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vendors_csv = os.path.join(batch_dir, 'vendor.csv')\n",
    "print(vendors_csv)\n",
    "\n",
    "df_dim_vendors = spark.read.format('csv').options(header='true', inferSchema='true').load(vendors_csv)\n",
    "df_dim_vendors.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f967a771-ba15-44db-b00f-e429f64bc25b",
   "metadata": {},
   "source": [
    "#### Make necessary transformations to the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "435fbce9-7aba-477c-82b9-9d3743681ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_key</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>account_number</th>\n",
       "      <th>preferred_vendor_status</th>\n",
       "      <th>credit_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Compete, Inc.</td>\n",
       "      <td>COMPETE0002</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Beaumont Bikes</td>\n",
       "      <td>BEAUMONT0001</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_key  vendor_id     vendor_name account_number  \\\n",
       "0           1         12   Compete, Inc.    COMPETE0002   \n",
       "1           1         13  Beaumont Bikes   BEAUMONT0001   \n",
       "\n",
       "   preferred_vendor_status  credit_rating  \n",
       "0                     True              1  \n",
       "1                    False              1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Rename columnss\n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_vendors = df_dim_vendors.withColumnRenamed(\"VendorID\", \"vendor_id\")\n",
    "df_dim_vendors = df_dim_vendors.withColumnRenamed(\"Name\", \"vendor_name\")\n",
    "df_dim_vendors = df_dim_vendors.withColumnRenamed(\"PreferredVendorStatus\", \"preferred_vendor_status\")\n",
    "df_dim_vendors = df_dim_vendors.withColumnRenamed(\"CreditRating\", \"credit_rating\")\n",
    "df_dim_vendors = df_dim_vendors.withColumnRenamed(\"AccountNumber\", \"account_number\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Add Primary Key column using SQL Windowing function: ROW_NUMBER() \n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_vendors.createOrReplaceTempView(\"vendors\")\n",
    "sql_vendors = f\"\"\"\n",
    "    SELECT *, ROW_NUMBER() OVER (PARTITION BY vendor_id ORDER BY vendor_id) AS vendor_key\n",
    "    FROM vendors;\n",
    "\"\"\"\n",
    "df_dim_vendors = spark.sql(sql_vendors)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "# ----------------------------------------------------------------------------------\n",
    "ordered_columns = ['vendor_key', 'vendor_id', 'vendor_name', 'account_number'\n",
    "                   , 'preferred_vendor_status', 'credit_rating']\n",
    "\n",
    "df_dim_vendors = df_dim_vendors[ordered_columns]\n",
    "df_dim_vendors.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c74ea50-71b3-44c1-a3ae-d6548c9d26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_vendors.write.saveAsTable(f\"{dest_database}.dim_vendors\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760f69b4-35f7-4ebe-b1ad-d91acd3b2592",
   "metadata": {},
   "source": [
    "### Populate the Employees Dimension\n",
    "Fetching the employee collection from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf4c3564-ee05-4527-afee-abe38649cb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>ContactID</th>\n",
       "      <th>CurrentFlag</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HireDate</th>\n",
       "      <th>LoginID</th>\n",
       "      <th>ManagerID</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>ModifiedDate</th>\n",
       "      <th>NationalIDNumber</th>\n",
       "      <th>SalariedFlag</th>\n",
       "      <th>SickLeaveHours</th>\n",
       "      <th>Title</th>\n",
       "      <th>VacationHours</th>\n",
       "      <th>rowguid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1972-05-15T00:00:00.000-04:00</td>\n",
       "      <td>1209</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1996-07-31T00:00:00.000-04:00</td>\n",
       "      <td>adventure-works\\guy1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2004-07-31T00:00:00.000-04:00</td>\n",
       "      <td>14417807</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>Production Technician - WC60</td>\n",
       "      <td>21</td>\n",
       "      <td>StDhqjfCdEm01ZNSR3N3GA==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1977-06-03T00:00:00.000-04:00</td>\n",
       "      <td>1030</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1997-02-26T00:00:00.000-05:00</td>\n",
       "      <td>adventure-works\\kevin0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S</td>\n",
       "      <td>2004-07-31T00:00:00.000-04:00</td>\n",
       "      <td>253022876</td>\n",
       "      <td>False</td>\n",
       "      <td>41</td>\n",
       "      <td>Marketing Assistant</td>\n",
       "      <td>42</td>\n",
       "      <td>QAJIG8CVD0GnF+splDyIhg==</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       BirthDate  ContactID  CurrentFlag  EmployeeID Gender  \\\n",
       "0  1972-05-15T00:00:00.000-04:00       1209         True           1      M   \n",
       "1  1977-06-03T00:00:00.000-04:00       1030         True           2      M   \n",
       "\n",
       "                        HireDate                 LoginID  ManagerID  \\\n",
       "0  1996-07-31T00:00:00.000-04:00    adventure-works\\guy1       16.0   \n",
       "1  1997-02-26T00:00:00.000-05:00  adventure-works\\kevin0        6.0   \n",
       "\n",
       "  MaritalStatus                   ModifiedDate NationalIDNumber  SalariedFlag  \\\n",
       "0             M  2004-07-31T00:00:00.000-04:00         14417807         False   \n",
       "1             S  2004-07-31T00:00:00.000-04:00        253022876         False   \n",
       "\n",
       "   SickLeaveHours                         Title  VacationHours  \\\n",
       "0              30  Production Technician - WC60             21   \n",
       "1              41           Marketing Assistant             42   \n",
       "\n",
       "                    rowguid  \n",
       "0  StDhqjfCdEm01ZNSR3N3GA==  \n",
       "1  QAJIG8CVD0GnF+splDyIhg==  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongodb_args[\"collection\"] = \"employee\"\n",
    "\n",
    "df_dim_employees = get_mongodb_dataframe(spark, **mongodb_args)\n",
    "df_dim_employees.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d3499a-e3f4-4a86-833e-88758053d25e",
   "metadata": {},
   "source": [
    "#### Make necessary transformations to the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f726959c-04e1-4108-8633-267c94f83777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_key</th>\n",
       "      <th>employee_id</th>\n",
       "      <th>title</th>\n",
       "      <th>gender</th>\n",
       "      <th>national_id_num</th>\n",
       "      <th>marital_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Vice President of Engineering</td>\n",
       "      <td>F</td>\n",
       "      <td>245797967</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Production Technician - WC10</td>\n",
       "      <td>M</td>\n",
       "      <td>844973625</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_key  employee_id                          title gender  \\\n",
       "0             1           12  Vice President of Engineering      F   \n",
       "1             1           13   Production Technician - WC10      M   \n",
       "\n",
       "  national_id_num marital_status  \n",
       "0       245797967              S  \n",
       "1       844973625              M  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Rename the 'id' column to 'customer_id' ------------------------------------------\n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_employees = df_dim_employees.withColumnRenamed(\"EmployeeID\", \"employee_id\")\n",
    "df_dim_employees = df_dim_employees.withColumnRenamed(\"Gender\", \"gender\")\n",
    "df_dim_employees = df_dim_employees.withColumnRenamed(\"NationalIDNumber\", \"national_id_num\")\n",
    "df_dim_employees = df_dim_employees.withColumnRenamed(\"MaritalStatus\", \"marital_status\")\n",
    "df_dim_employees = df_dim_employees.withColumnRenamed(\"Title\", \"title\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Add Primary Key column using the SQL Windowing function: ROW_NUMBER() \n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_employees.createOrReplaceTempView(\"employees\")\n",
    "sql_employees = f\"\"\"\n",
    "    SELECT *, ROW_NUMBER() OVER (PARTITION BY employee_id ORDER BY employee_id) AS employee_key\n",
    "    FROM employees;\n",
    "\"\"\"\n",
    "df_dim_employees = spark.sql(sql_employees)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "# ----------------------------------------------------------------------------------\n",
    "ordered_columns = ['employee_key', 'employee_id', 'title', 'gender', 'national_id_num', 'marital_status']\n",
    "\n",
    "df_dim_employees = df_dim_employees[ordered_columns]\n",
    "df_dim_employees.toPandas().head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9be0b7b9-99f8-4a5c-a773-06cf2afa15d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_employees.write.saveAsTable(f\"{dest_database}.dim_employees\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b33716c-760b-47bb-a567-c47785ec559f",
   "metadata": {},
   "source": [
    "### Populate the Product Dimension\n",
    "Fetching product table from MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9908d75d-ba79-4309-b044-f591e23c00d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Name</th>\n",
       "      <th>ProductNumber</th>\n",
       "      <th>MakeFlag</th>\n",
       "      <th>FinishedGoodsFlag</th>\n",
       "      <th>Color</th>\n",
       "      <th>SafetyStockLevel</th>\n",
       "      <th>ReorderPoint</th>\n",
       "      <th>StandardCost</th>\n",
       "      <th>ListPrice</th>\n",
       "      <th>...</th>\n",
       "      <th>Class</th>\n",
       "      <th>Style</th>\n",
       "      <th>ProductSubcategoryID</th>\n",
       "      <th>ProductModelID</th>\n",
       "      <th>SellStartDate</th>\n",
       "      <th>SellEndDate</th>\n",
       "      <th>DiscontinuedDate</th>\n",
       "      <th>rowguid</th>\n",
       "      <th>ModifiedDate</th>\n",
       "      <th>product_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Adjustable Race</td>\n",
       "      <td>AR-5381</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>[183, 21, 66, 105, 247, 8, 13, 76, 172, 177, 2...</td>\n",
       "      <td>2004-03-11 10:01:36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bearing Ball</td>\n",
       "      <td>BA-8327</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1000</td>\n",
       "      <td>750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998-06-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>[32, 60, 174, 88, 58, 79, 73, 71, 167, 212, 21...</td>\n",
       "      <td>2004-03-11 10:01:36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID             Name ProductNumber  MakeFlag  FinishedGoodsFlag  \\\n",
       "0          1  Adjustable Race       AR-5381     False              False   \n",
       "1          2     Bearing Ball       BA-8327     False              False   \n",
       "\n",
       "  Color  SafetyStockLevel  ReorderPoint  StandardCost  ListPrice  ... Class  \\\n",
       "0  None              1000           750           0.0        0.0  ...  None   \n",
       "1  None              1000           750           0.0        0.0  ...  None   \n",
       "\n",
       "  Style ProductSubcategoryID ProductModelID  SellStartDate SellEndDate  \\\n",
       "0  None                  NaN            NaN     1998-06-01         NaT   \n",
       "1  None                  NaN            NaN     1998-06-01         NaT   \n",
       "\n",
       "  DiscontinuedDate                                            rowguid  \\\n",
       "0              NaT  [183, 21, 66, 105, 247, 8, 13, 76, 172, 177, 2...   \n",
       "1              NaT  [32, 60, 174, 88, 58, 79, 73, 71, 167, 212, 21...   \n",
       "\n",
       "         ModifiedDate  product_key  \n",
       "0 2004-03-11 10:01:36            1  \n",
       "1 2004-03-11 10:01:36            1  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_product = f\"SELECT *, ROW_NUMBER() OVER (PARTITION BY ProductID ORDER BY ProductID) AS product_key FROM {mysql_args['db_name']}.product\"\n",
    "df_dim_products = get_mysql_dataframe(spark, sql_product, **mysql_args)\n",
    "\n",
    "df_dim_products.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48067a-83d4-4ee7-b49a-b3c10206bc5d",
   "metadata": {},
   "source": [
    "#### Temporary tables for Product Sub Category and Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f108433-90f6-4f10-901f-e3ed852173e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductSubcategoryID</th>\n",
       "      <th>ProductCategoryID</th>\n",
       "      <th>Name</th>\n",
       "      <th>rowguid</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mountain Bikes</td>\n",
       "      <td>[222, 74, 54, 45, 74, 38, 60, 67, 176, 146, 79...</td>\n",
       "      <td>1998-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Road Bikes</td>\n",
       "      <td>[192, 16, 3, 0, 200, 188, 196, 66, 176, 195, 6...</td>\n",
       "      <td>1998-06-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductSubcategoryID  ProductCategoryID            Name  \\\n",
       "0                     1                  1  Mountain Bikes   \n",
       "1                     2                  1      Road Bikes   \n",
       "\n",
       "                                             rowguid ModifiedDate  \n",
       "0  [222, 74, 54, 45, 74, 38, 60, 67, 176, 146, 79...   1998-06-01  \n",
       "1  [192, 16, 3, 0, 200, 188, 196, 66, 176, 195, 6...   1998-06-01  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_product_subcat = f\"SELECT * FROM {mysql_args['db_name']}.productsubcategory\"\n",
    "df_product_subcat = get_mysql_dataframe(spark, sql_product_subcat, **mysql_args)\n",
    "\n",
    "df_product_subcat.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49a39546-43e6-4d65-9b83-9fcff2c328d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductCategoryID</th>\n",
       "      <th>Name</th>\n",
       "      <th>rowguid</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>[92, 162, 189, 207, 113, 223, 167, 71, 184, 27...</td>\n",
       "      <td>1998-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Components</td>\n",
       "      <td>[141, 130, 87, 198, 8, 216, 186, 74, 145, 163,...</td>\n",
       "      <td>1998-06-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductCategoryID        Name  \\\n",
       "0                  1       Bikes   \n",
       "1                  2  Components   \n",
       "\n",
       "                                             rowguid ModifiedDate  \n",
       "0  [92, 162, 189, 207, 113, 223, 167, 71, 184, 27...   1998-06-01  \n",
       "1  [141, 130, 87, 198, 8, 216, 186, 74, 145, 163,...   1998-06-01  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_product_cat = f\"SELECT * FROM {mysql_args['db_name']}.productcategory\"\n",
    "df_product_cat = get_mysql_dataframe(spark, sql_product_cat, **mysql_args)\n",
    "\n",
    "df_product_cat.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba705c-f831-4310-a5c5-d4c4ed59edf7",
   "metadata": {},
   "source": [
    "#### Make necessary transformations to the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7201efea-367a-4bc2-8716-3a4ef4536664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_key</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>safety_stock_level</th>\n",
       "      <th>reorder_point</th>\n",
       "      <th>standard_cost</th>\n",
       "      <th>list_price</th>\n",
       "      <th>product_line</th>\n",
       "      <th>weight</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>771</td>\n",
       "      <td>Mountain-100 Silver, 38</td>\n",
       "      <td>100</td>\n",
       "      <td>75</td>\n",
       "      <td>1912.1544</td>\n",
       "      <td>3399.99</td>\n",
       "      <td>M</td>\n",
       "      <td>20.35</td>\n",
       "      <td>Bikes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>772</td>\n",
       "      <td>Mountain-100 Silver, 42</td>\n",
       "      <td>100</td>\n",
       "      <td>75</td>\n",
       "      <td>1912.1544</td>\n",
       "      <td>3399.99</td>\n",
       "      <td>M</td>\n",
       "      <td>20.77</td>\n",
       "      <td>Bikes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_key  product_id             product_name  safety_stock_level  \\\n",
       "0           1         771  Mountain-100 Silver, 38                 100   \n",
       "1           1         772  Mountain-100 Silver, 42                 100   \n",
       "\n",
       "   reorder_point  standard_cost  list_price product_line weight category  \n",
       "0             75      1912.1544     3399.99           M   20.35    Bikes  \n",
       "1             75      1912.1544     3399.99           M   20.77    Bikes  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Rename columns\n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_products = df_dim_products.withColumnRenamed(\"ProductID\", \"product_id\")\n",
    "df_dim_products = df_dim_products.withColumnRenamed(\"Name\", \"product_name\")\n",
    "df_dim_products = df_dim_products.withColumnRenamed(\"SafetyStockLevel\", \"safety_stock_level\")\n",
    "df_dim_products = df_dim_products.withColumnRenamed(\"ReorderPoint\", \"reorder_point\")\n",
    "df_dim_products = df_dim_products.withColumnRenamed(\"StandardCost\", \"standard_cost\")\n",
    "df_dim_products = df_dim_products.withColumnRenamed(\"ListPrice\", \"list_price\")\n",
    "df_dim_products = df_dim_products.withColumnRenamed(\"ProductLine\", \"product_line\")\n",
    "df_dim_products = df_dim_products.withColumnRenamed(\"Weight\", \"weight\")\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Join subcategory and category to get category name\n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_products = df_dim_products \\\n",
    "    .join(df_product_subcat, on=\"ProductSubcategoryID\", how=\"inner\") \\\n",
    "    .join(df_product_cat, on=\"ProductCategoryID\", how = 'inner') \\\n",
    "    .select(\n",
    "        df_dim_products[\"*\"],\n",
    "        df_product_cat[\"name\"].alias(\"category\")\n",
    "    )\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Drop unwanted columns (description and attachments)\n",
    "# ----------------------------------------------------------------------------------\n",
    "df_dim_products.drop('ProductSubcategoryID','MakeFlag','FinishedGoodsFlags','Color','Size','SizeUnitMeasureCode','WeightUnitMeasureCode','DaysToManufacture','Class','Style','ProductSubcategoryID','ProductModelID','SellStartDate','SellEndDate','DiscontinuedDate','rowguid','ModifiedDate')\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Reorder Columns and display the first two rows in a Pandas dataframe\n",
    "# ----------------------------------------------------------------------------------\n",
    "reordered_columns = ['product_key','product_id', 'product_name','safety_stock_level'\n",
    "                     ,'reorder_point','standard_cost','list_price'\n",
    "                     ,'product_line','weight','category']\n",
    "\n",
    "df_dim_products = df_dim_products[reordered_columns]\n",
    "df_dim_products.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "953a4f75-6092-4782-8f58-a73e049ec844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_products.write.saveAsTable(f\"{dest_database}.dim_products\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c4ee0-53db-4534-9ee5-018dd5ac02c2",
   "metadata": {},
   "source": [
    "### Populate the Date Dimension\n",
    "Fetching the dim_date table from MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30079cec-42a0-47da-8285-045158d5a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dim_date = f\"SELECT * FROM {mysql_args['db_name']}.dim_date\"\n",
    "df_dim_date = get_mysql_dataframe(spark, sql_dim_date, **mysql_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c5a8aed-a011-4e41-8182-5f811ae080a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_date.write.saveAsTable(f\"{dest_database}.dim_date\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bfe0c10-8e2e-4797-b177-0649feccb75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|            date_key|      int|   NULL|\n",
      "|           full_date|     date|   NULL|\n",
      "|           date_name| char(11)|   NULL|\n",
      "|        date_name_us| char(11)|   NULL|\n",
      "|        date_name_eu| char(11)|   NULL|\n",
      "|         day_of_week|  tinyint|   NULL|\n",
      "|    day_name_of_week| char(10)|   NULL|\n",
      "|        day_of_month|  tinyint|   NULL|\n",
      "|         day_of_year|      int|   NULL|\n",
      "|     weekday_weekend| char(10)|   NULL|\n",
      "|        week_of_year|  tinyint|   NULL|\n",
      "|          month_name| char(10)|   NULL|\n",
      "|       month_of_year|  tinyint|   NULL|\n",
      "|is_last_day_of_month|  char(1)|   NULL|\n",
      "|    calendar_quarter|  tinyint|   NULL|\n",
      "|       calendar_year|      int|   NULL|\n",
      "| calendar_year_month| char(10)|   NULL|\n",
      "|   calendar_year_qtr| char(10)|   NULL|\n",
      "|fiscal_month_of_year|  tinyint|   NULL|\n",
      "|      fiscal_quarter|  tinyint|   NULL|\n",
      "+--------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_key</th>\n",
       "      <th>full_date</th>\n",
       "      <th>date_name</th>\n",
       "      <th>date_name_us</th>\n",
       "      <th>date_name_eu</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_name_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>weekday_weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>is_last_day_of_month</th>\n",
       "      <th>calendar_quarter</th>\n",
       "      <th>calendar_year</th>\n",
       "      <th>calendar_year_month</th>\n",
       "      <th>calendar_year_qtr</th>\n",
       "      <th>fiscal_month_of_year</th>\n",
       "      <th>fiscal_quarter</th>\n",
       "      <th>fiscal_year</th>\n",
       "      <th>fiscal_year_month</th>\n",
       "      <th>fiscal_year_qtr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000101</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000/01/01</td>\n",
       "      <td>01/01/2000</td>\n",
       "      <td>01/01/2000</td>\n",
       "      <td>7</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>2000Q1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-07</td>\n",
       "      <td>2000Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000102</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>2000/01/02</td>\n",
       "      <td>01/02/2000</td>\n",
       "      <td>02/01/2000</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>2000Q1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000-07</td>\n",
       "      <td>2000Q3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_key   full_date    date_name date_name_us date_name_eu  day_of_week  \\\n",
       "0  20000101  2000-01-01  2000/01/01   01/01/2000   01/01/2000             7   \n",
       "1  20000102  2000-01-02  2000/01/02   01/02/2000   02/01/2000             1   \n",
       "\n",
       "  day_name_of_week  day_of_month  day_of_year weekday_weekend  ...  \\\n",
       "0       Saturday               1            1      Weekend     ...   \n",
       "1       Sunday                 2            2      Weekend     ...   \n",
       "\n",
       "   is_last_day_of_month calendar_quarter  calendar_year calendar_year_month  \\\n",
       "0                     N                1           2000          2000-01      \n",
       "1                     N                1           2000          2000-01      \n",
       "\n",
       "   calendar_year_qtr  fiscal_month_of_year fiscal_quarter fiscal_year  \\\n",
       "0         2000Q1                         7              3        2000   \n",
       "1         2000Q1                         7              3        2000   \n",
       "\n",
       "   fiscal_year_month  fiscal_year_qtr  \n",
       "0         2000-07          2000Q3      \n",
       "1         2000-07          2000Q3      \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE EXTENDED {dest_database}.dim_date;\").show()\n",
    "spark.sql(f\"SELECT * FROM {dest_database}.dim_date LIMIT 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e371558a-9ecb-4c21-aa75-91bd061b3657",
   "metadata": {},
   "source": [
    "#### Temporary table for Purchase Order Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbc72af5-770d-4a57-af1c-af925b2c9b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PurchaseOrderID</th>\n",
       "      <th>PurchaseOrderDetailID</th>\n",
       "      <th>DueDate</th>\n",
       "      <th>OrderQty</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>LineTotal</th>\n",
       "      <th>ReceivedQty</th>\n",
       "      <th>RejectedQty</th>\n",
       "      <th>StockedQty</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-05-31</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50.26</td>\n",
       "      <td>201.04</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2001-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2001-05-31</td>\n",
       "      <td>3</td>\n",
       "      <td>359</td>\n",
       "      <td>45.12</td>\n",
       "      <td>135.36</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2001-05-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PurchaseOrderID  PurchaseOrderDetailID    DueDate  OrderQty  ProductID  \\\n",
       "0                1                      1 2001-05-31         4          1   \n",
       "1                2                      2 2001-05-31         3        359   \n",
       "\n",
       "   UnitPrice  LineTotal ReceivedQty RejectedQty StockedQty ModifiedDate  \n",
       "0      50.26     201.04        3.00        0.00       3.00   2001-05-24  \n",
       "1      45.12     135.36        3.00        0.00       3.00   2001-05-24  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_po_details = f\"SELECT * FROM {mysql_args['db_name']}.purchaseorderdetail\"\n",
    "df_po_details = get_mysql_dataframe(spark, sql_po_details, **mysql_args)\n",
    "\n",
    "df_po_details.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550c0cc-f34e-4d83-9d21-34b31ec6076d",
   "metadata": {},
   "source": [
    "### Verify dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8219b512-df40-4181-8872-ff08003b7214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "      <th>tableName</th>\n",
       "      <th>isTemporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adventureworks_dlh</td>\n",
       "      <td>dim_date</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adventureworks_dlh</td>\n",
       "      <td>dim_employees</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adventureworks_dlh</td>\n",
       "      <td>dim_products</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adventureworks_dlh</td>\n",
       "      <td>dim_vendors</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>employees</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>vendors</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            namespace      tableName  isTemporary\n",
       "0  adventureworks_dlh       dim_date        False\n",
       "1  adventureworks_dlh  dim_employees        False\n",
       "2  adventureworks_dlh   dim_products        False\n",
       "3  adventureworks_dlh    dim_vendors        False\n",
       "4                          employees         True\n",
       "5                            vendors         True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"USE {dest_database};\")\n",
    "spark.sql(\"SHOW TABLES\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d1224-2c4e-4597-957f-7b08db03fe05",
   "metadata": {},
   "source": [
    "## Part 3: Integrating reference data with real-time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9463ff7-08ab-4cbf-ad76-64a9a46e3dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size</th>\n",
       "      <th>modification_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>po_part_1.json</td>\n",
       "      <td>416407</td>\n",
       "      <td>2025-05-07 18:39:10.284090996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>po_part_2.json</td>\n",
       "      <td>417429</td>\n",
       "      <td>2025-05-07 18:39:11.674629450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>po_part_3.json</td>\n",
       "      <td>416764</td>\n",
       "      <td>2025-05-07 18:39:12.969245434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name    size             modification_time\n",
       "0  po_part_1.json  416407 2025-05-07 18:39:10.284090996\n",
       "1  po_part_2.json  417429 2025-05-07 18:39:11.674629450\n",
       "2  po_part_3.json  416764 2025-05-07 18:39:12.969245434"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_info(stream_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5594be7-3c13-4a14-a76f-5ada9715dcac",
   "metadata": {},
   "source": [
    "### Creating the Bronze Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3e8627-863e-476b-abd6-fa812908fa63",
   "metadata": {},
   "source": [
    "#### Read raw JSON files into stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afe9f0e6-65ff-4318-9b63-57f5e5621bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_purchase_orders = (\n",
    "    spark.readStream \\\n",
    "    .option(\"maxFilesPerTrigger\", 1) \\\n",
    "    .option(\"multiLine\", \"false\") \\\n",
    "    .json(stream_dir)\n",
    ")\n",
    "\n",
    "df_purchase_orders.isStreaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8bbf79-6833-4dc2-9dd1-f0eacabc27f2",
   "metadata": {},
   "source": [
    "#### Write streaming data to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "137e4ce5-5ed9-43be-9eb7-2623566e1348",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_checkpoint_bronze = os.path.join(purchase_orders_output_bronze, '_checkpoint')\n",
    "\n",
    "purchase_orders_bronze_query = (\n",
    "    df_purchase_orders\n",
    "    .withColumn(\"receipt_time\", current_timestamp())\n",
    "    .withColumn(\"source_file\", input_file_name())\n",
    "    \n",
    "    .writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .queryName(\"purchase_orders_bronze\")\n",
    "    .trigger(availableNow = True) \\\n",
    "    .option(\"checkpointLocation\", purchase_orders_checkpoint_bronze) \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .start(purchase_orders_output_bronze)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ca25d46-2db0-4a99-ba8d-26c217cc71de",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_bronze_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676a6f7-83e6-43e7-82a2-9417e91ae4c9",
   "metadata": {},
   "source": [
    "### Creating the Silver Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e36a87-31a4-422e-a805-eb10005124d7",
   "metadata": {},
   "source": [
    "#### Preparing the role-playing dimension keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37ea10cd-5014-4191-94ef-de56c1ea3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dim_order_date = df_dim_date.select(col(\"date_key\").alias(\"order_date_key\"), col(\"full_date\").alias(\"order_full_date\"))\n",
    "df_dim_ship_date = df_dim_date.select(col(\"date_key\").alias(\"ship_date_key\"), col(\"full_date\").alias(\"ship_full_date\"))\n",
    "df_dim_due_date = df_dim_date.select(col(\"date_key\").alias(\"due_date_key\"), col(\"full_date\").alias(\"due_full_date\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979740d-d27d-47b1-8f0a-14f6d936e14c",
   "metadata": {},
   "source": [
    "#### Silver query to join streaming with the batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd3dec1e-58f1-41f7-aa9d-300979b8006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase_orders_silver = spark.readStream.format(\"parquet\").load(purchase_orders_output_bronze) \\\n",
    "    .join(df_po_details, 'PurchaseOrderID') \\\n",
    "    .join(df_dim_products, df_dim_products.product_id == col(\"ProductID\")) \\\n",
    "    .join(df_dim_employees, df_dim_employees.employee_id == col(\"EmployeeID\")) \\\n",
    "    .join(df_dim_vendors, df_dim_vendors.vendor_id == col(\"VendorID\")) \\\n",
    "    .join(df_dim_order_date, df_dim_order_date.order_full_date.cast(DateType()) == col(\"OrderDate\").cast(DateType()), \"inner\") \\\n",
    "    .join(df_dim_due_date, df_dim_due_date.due_full_date.cast(DateType()) == col(\"DueDate\").cast(DateType()), \"inner\") \\\n",
    "    .join(df_dim_ship_date, df_dim_ship_date.ship_full_date.cast(DateType()) == col(\"ShipDate\").cast(DateType()), \"left_outer\") \\\n",
    "    .select(col(\"PurchaseOrderID\").cast(LongType()).alias(\"purchase_order_id\"), \\\n",
    "            df_po_details.OrderQty.cast(LongType()).alias(\"order_qty\"), \\\n",
    "            df_po_details.UnitPrice.cast(LongType()).alias(\"unit_price\"), \\\n",
    "            df_po_details.LineTotal.cast(LongType()).alias(\"line_total\"), \\\n",
    "            df_dim_products.product_key.cast(IntegerType()), \\\n",
    "            df_dim_vendors.vendor_key.cast(IntegerType()), \\\n",
    "            df_dim_employees.employee_key.cast(IntegerType()), \\\n",
    "            df_dim_order_date.order_date_key.cast(LongType()), \\\n",
    "            df_dim_due_date.due_date_key.cast(LongType()), \\\n",
    "            df_dim_ship_date.ship_date_key.cast(LongType()), \\\n",
    "            col(\"SubTotal\").alias(\"subtotal\"), \\\n",
    "            col(\"TaxAmt\").alias(\"tax_amt\"), \\\n",
    "            col(\"Freight\").alias(\"freight\"), \\\n",
    "            col(\"TotalDue\").alias(\"total_due\") \\\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f92c7c33-bdb4-47e7-938d-8f43694fcbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_purchase_orders_silver.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fc4f3d7-72f2-4f86-96c9-ed2b9672788e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- purchase_order_id: long (nullable = true)\n",
      " |-- order_qty: long (nullable = true)\n",
      " |-- unit_price: long (nullable = true)\n",
      " |-- line_total: long (nullable = true)\n",
      " |-- product_key: integer (nullable = true)\n",
      " |-- vendor_key: integer (nullable = false)\n",
      " |-- employee_key: integer (nullable = false)\n",
      " |-- order_date_key: long (nullable = true)\n",
      " |-- due_date_key: long (nullable = true)\n",
      " |-- ship_date_key: long (nullable = true)\n",
      " |-- subtotal: double (nullable = true)\n",
      " |-- tax_amt: double (nullable = true)\n",
      " |-- freight: double (nullable = true)\n",
      " |-- total_due: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_purchase_orders_silver.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9857a7-cd41-4266-abb5-c430f78f953e",
   "metadata": {},
   "source": [
    "#### Write the transformed streaming data to the Data Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "186c9f48-e66c-4574-8741-346750064601",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_checkpoint_silver = os.path.join(purchase_orders_output_silver, '_checkpoint')\n",
    "\n",
    "purchase_orders_silver_query = (\n",
    "    df_purchase_orders_silver.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .queryName(\"purchase_orders_silver\")\n",
    "    .trigger(availableNow = True) \\\n",
    "    .option(\"checkpointLocation\", purchase_orders_checkpoint_silver) \\\n",
    "    .option(\"compression\", \"snappy\") \\\n",
    "    .start(purchase_orders_output_silver)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70b8070a-6881-4feb-adc8-e83d62131fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_silver_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7624b0-4a17-4474-b7c3-b93c90e8d19f",
   "metadata": {},
   "source": [
    "### Creating Gold Layer\n",
    "\n",
    "Creating a new Gold table using the PySpark API. This table includes the number of products sold per category for each month, sorted by the month number when orders were placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db018bf4-3f92-40b8-bfea-cb44d0b5dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase_orders_by_product_category_gold = spark.readStream.format(\"parquet\").load(purchase_orders_output_silver) \\\n",
    ".join(df_dim_products, \"product_key\") \\\n",
    ".join(df_dim_date, df_dim_date.date_key.cast(IntegerType()) == col(\"order_date_key\").cast(IntegerType())) \\\n",
    ".groupBy(\"month_of_year\", \"category\", \"month_name\") \\\n",
    ".agg(sum(\"order_qty\").alias(\"product_count\")) \\\n",
    ".orderBy(asc(\"month_of_year\"), desc(\"product_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f6cbfdc-28de-44d8-b9e2-5df79e49ea40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month_of_year: byte (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- month_name: string (nullable = true)\n",
      " |-- product_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_purchase_orders_by_product_category_gold.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d84698-36b3-4ac2-9777-f53e9d86c957",
   "metadata": {},
   "source": [
    "#### Writing the streaming data to a parquet file in \"complete\" mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "130eb891-30df-4d28-8ab0-97308c264124",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_orders_gold_query = (\n",
    "    df_purchase_orders_by_product_category_gold.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .queryName(\"fact_purchase_orders_by_product_category\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea3bba2f-5785-41f3-a4b4-7a65905245ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stream has processed 1 batchs\n"
     ]
    }
   ],
   "source": [
    "wait_until_stream_is_ready(purchase_orders_gold_query, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca99005-2ecb-4ce6-a2be-0e544338c203",
   "metadata": {},
   "source": [
    "#### Query the Gold Data from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df53a92d-f0e4-4837-91cd-ed5a2a50263c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month_of_year: byte (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- month_name: string (nullable = true)\n",
      " |-- product_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fact_purchase_orders_by_product_category = spark.sql(\"SELECT * FROM fact_purchase_orders_by_product_category\")\n",
    "df_fact_purchase_orders_by_product_category.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0decfeb-c66f-4874-813e-d34a7ecb3397",
   "metadata": {},
   "source": [
    "#### Creating the final selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f65984f7-7d41-461a-b0a0-e12618f4189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_purchase_orders_by_product_category_gold_final = df_fact_purchase_orders_by_product_category \\\n",
    ".select(col(\"month_name\").alias(\"Month\"), \\\n",
    "        col(\"month_of_year\").alias(\"Month Num\"), \\\n",
    "        col(\"category\").alias(\"Product Category\"), \\\n",
    "        col(\"product_count\").alias(\"Product Count\")) \\\n",
    ".orderBy(asc(\"Month Num\"), desc(\"Product Count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9256726c-d531-476a-9a3b-6b7584381e23",
   "metadata": {},
   "source": [
    "#### Loading the final results into a new table and displaying the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f118d5a-5e69-4b5d-bc6b-e03d595afeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Product Category</th>\n",
       "      <th>Product Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January</td>\n",
       "      <td>Components</td>\n",
       "      <td>10129060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>7332230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>2645650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>January</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2192110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>February</td>\n",
       "      <td>Components</td>\n",
       "      <td>10784320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>February</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>7806560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>February</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>2816800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>February</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2333920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>March</td>\n",
       "      <td>Components</td>\n",
       "      <td>11021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>March</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>7978250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>March</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>2878750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>March</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2385250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>April</td>\n",
       "      <td>Components</td>\n",
       "      <td>11824160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>April</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>8559280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>April</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>3088400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>April</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2558960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>May</td>\n",
       "      <td>Components</td>\n",
       "      <td>14346040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>May</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>10384820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>May</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>3747100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>May</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>3104740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>June</td>\n",
       "      <td>Components</td>\n",
       "      <td>14935640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>June</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>10811620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>June</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>3901100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>June</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>3232340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>July</td>\n",
       "      <td>Components</td>\n",
       "      <td>13814060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>July</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>9999730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>July</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>3608150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>July</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2989610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>August</td>\n",
       "      <td>Components</td>\n",
       "      <td>15451540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>August</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>11185070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>August</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>4035850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>August</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>3343990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>September</td>\n",
       "      <td>Components</td>\n",
       "      <td>13756440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>September</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>9958020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>September</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>3593100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>September</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2977140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>October</td>\n",
       "      <td>Components</td>\n",
       "      <td>7975680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>October</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>5773440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>October</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>2083200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>October</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1726080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>November</td>\n",
       "      <td>Components</td>\n",
       "      <td>5248780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>November</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>3799490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>November</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>1370950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>November</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1135930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>December</td>\n",
       "      <td>Components</td>\n",
       "      <td>7164980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>December</td>\n",
       "      <td>Bikes</td>\n",
       "      <td>5186590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>December</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>1871450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>December</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1550630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Month Product Category  Product Count\n",
       "0   January          Components       10129060\n",
       "1   January               Bikes        7332230\n",
       "2   January            Clothing        2645650\n",
       "3   January         Accessories        2192110\n",
       "4   February         Components       10784320\n",
       "5   February              Bikes        7806560\n",
       "6   February           Clothing        2816800\n",
       "7   February        Accessories        2333920\n",
       "8   March            Components       11021500\n",
       "9   March                 Bikes        7978250\n",
       "10  March              Clothing        2878750\n",
       "11  March           Accessories        2385250\n",
       "12  April            Components       11824160\n",
       "13  April                 Bikes        8559280\n",
       "14  April              Clothing        3088400\n",
       "15  April           Accessories        2558960\n",
       "16  May              Components       14346040\n",
       "17  May                   Bikes       10384820\n",
       "18  May                Clothing        3747100\n",
       "19  May             Accessories        3104740\n",
       "20  June             Components       14935640\n",
       "21  June                  Bikes       10811620\n",
       "22  June               Clothing        3901100\n",
       "23  June            Accessories        3232340\n",
       "24  July             Components       13814060\n",
       "25  July                  Bikes        9999730\n",
       "26  July               Clothing        3608150\n",
       "27  July            Accessories        2989610\n",
       "28  August           Components       15451540\n",
       "29  August                Bikes       11185070\n",
       "30  August             Clothing        4035850\n",
       "31  August          Accessories        3343990\n",
       "32  September        Components       13756440\n",
       "33  September             Bikes        9958020\n",
       "34  September          Clothing        3593100\n",
       "35  September       Accessories        2977140\n",
       "36  October          Components        7975680\n",
       "37  October               Bikes        5773440\n",
       "38  October            Clothing        2083200\n",
       "39  October         Accessories        1726080\n",
       "40  November         Components        5248780\n",
       "41  November              Bikes        3799490\n",
       "42  November           Clothing        1370950\n",
       "43  November        Accessories        1135930\n",
       "44  December         Components        7164980\n",
       "45  December              Bikes        5186590\n",
       "46  December           Clothing        1871450\n",
       "47  December        Accessories        1550630"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_purchase_orders_by_product_category_gold_final.write.saveAsTable(f\"{dest_database}.fact_purchase_orders_by_product_category\", mode=\"overwrite\")\n",
    "spark.sql(f\"SELECT Month, `Product Category`, `Product Count` FROM {dest_database}.fact_purchase_orders_by_product_category ORDER BY `Month Num` ASC, `Product Count` DESC\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f086c-cc21-451b-bcf6-75b90c1e4de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (3.12-env)",
   "language": "python",
   "name": "3.12-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
